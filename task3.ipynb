{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 \n",
    " > When we capture LiDAR data from a moving vehicle, each scan comes with its own local coordinate system, where the car/sensor is centered at x=0, y=0, z=0. However, aligning these scans into a unified world coordinate system brings significant benefits for visualization and downstream tasks that benefit from temporal information. In this context, 1) familiarize yourself with the concept of \"ego-motion compensation\" concerning LiDAR scans captured from a moving vehicle and 2) utilize the provided pose data from SemanticKITTI to create a function that compensates for the vehicle's ego-motion and aligns each scan into a shared world coordinate system. You can find anything you need for this purpose in this github repository: https://github.com/PRBonn/semantic-kitti-api , but its no free lunch, you have to search a bit and understand :). Finally, visualize a sequence of point clouds both with and without ego-motion compensation in two ways: A) Simply visualize 20 subsequent frames at the same time, B) visualize one frame at a time using your visualizer from Task 2. \n",
    "=> What difference do you observe when visualizing a point cloud sequence with and without ego-motion compensation? \n",
    "\n",
    "In this task we aim to visualize the LiDAR data from SemanticKITTI dataset with ego-motion compenstation. In the previous task, the coordinate system of the visualization was fixed at scanner i.e. (0,0,0) was defined to be the position of LiDAR scanner.<br> Now we want to have a global coordinate system for all sequences. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordinate Transformation\n",
    "A point  $\\mathbf{P}$ in 3d space can be represented  as a vector with 3 elements $\\mathbf{p} = (p_x, p_y, p_z)$.\n",
    "<br>Each element corresponds to its coordinate along one of the axes (x, y or z)\n",
    "$$\n",
    "\\mathbf{P} =\n",
    "\\begin{bmatrix}\n",
    "p_x \\\\\n",
    "p_y \\\\\n",
    "p_z\n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rotate a point in 3D space, is to multiply a rotation matrix with the position vector of a point. Formally, rotaion is a form of linar transformation as we morph(squeeze or stretch) the 3D space in a linear fashion.\n",
    "\n",
    "$$\n",
    "\\mathbf{p}' = \\mathbf{R}\\mathbf{p}\n",
    "$$\n",
    "with $\\mathbf{R}$ a \\(3 $\\times$ 3\\) rotation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For coordinate transformation, rotation is not enough. We also need a component for translation\n",
    "Thus coordinate transformations can be represented by \n",
    "$$\n",
    "{}^{a}\\mathbf{p} = {}^{a}\\mathbf{r}_{b} + {}^{a}\\mathbf{R}_{b} {}^{b}\\mathbf{p}\n",
    "$$\n",
    "\n",
    "where <br>\n",
    "$ ^{a}\\mathbf{p}$ is the position vector of point $\\mathbf{p}$ in coordinate system $\\mathbf{S}_{a}$ <br>\n",
    "$^{a}\\mathbf{r}_{b}$ is the translation vector from coordinate system $\\mathbf{S}_{a}$ to $\\mathbf{S}_{b}$  <br>\n",
    "$^{a}\\mathbf{R}_{b}$ is the rotation matrix between $\\mathbf{S}_{a}$ and  $\\mathbf{S}_{b}$ <br>\n",
    "$^{b}\\mathbf{p}$ is the position vector of point $\\mathbf{p}$ in coordinate system $\\mathbf{S}_{b}$<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homogenous Transformation\n",
    "The above formula works just fine, but there is a more concise way to do this.\n",
    "First we define something called a transformation matrix.\n",
    "$$\n",
    "{}^{a}\\mathbf{T}_{b} = \\begin{pmatrix}\n",
    "{}^{a}\\mathbf{R}_{b} & {}^{a}\\mathbf{r}_{b} \\\\\n",
    "\\mathbf{0}^{T} & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "<br> ${}^{a}\\mathbf{T}_{b} \\in \\mathbb{R}^{4 \\times 4}$ is the transformation matrix from $\\mathbf{S}_{a}$ to $\\mathbf{S}_{b}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also redefine the position vector to \n",
    "$$\n",
    "{}^{a}\\hat{\\mathbf{p}} = \\begin{pmatrix}\n",
    "{}^{a}\\mathbf{p} \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "such that ${}^{a}\\hat{\\mathbf{p}} \\in \\mathbb{R}^{4 \\times 1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the final equation for transformation from coordinate system $\\mathbf{S}_{b}$ to $\\mathbf{S}_{a}$ becomes\n",
    "\n",
    "$$\n",
    "{}^{a}\\hat{\\mathbf{p}} = {}^{a}\\mathbf{T}_{b} \\, {}^{b}\\hat{\\mathbf{p}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of point clouds\n",
    "\n",
    "Now we are given pose data for each sequence. This means we have the transformation matrix for each sequence. Thus all it remains is to multiply each point of a sequence with the transformation matrix and then visualize the entire scene after we are done commputing the new coordinates for each point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "+ Use arrow keys \"left\" and \"right\" to go forward or backward by 1 sequence\n",
    "+ Use 'n' to go forward 20 sequences\n",
    "+ Use  'b' to go backward 20 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "from io import StringIO\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class SemanticKITTIVisualizer:\n",
    "    \"\"\"\n",
    "    A class to visualize SemanticKITTI dataset using Open3D.\n",
    "\n",
    "    Attributes:\n",
    "        base_dir (str): Base directory of the dataset.\n",
    "        seq_idx (str): Sequence index.\n",
    "        color_map (dict): Dictionary mapping labels to colors.\n",
    "        view_status_file (str): Path to the view status file.\n",
    "        point_size (int): Point size for visualization.\n",
    "        scan_dir (str): Directory containing the scan files.\n",
    "        label_dir (str): Directory containing the label files.\n",
    "        pose_file (str): Path to the poses file.\n",
    "        scan_files (list): List of scan file names.\n",
    "        label_files (list): List of label file names.\n",
    "        pcd (o3d.geometry.PointCloud): Open3D point cloud object.\n",
    "        geometry_added (bool): Flag to check if geometry is already added to the visualizer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_dir: str, seq_idx: str, color_map_file: str, view_status_file: str, point_size: int) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the SemanticKITTIVisualizer class.\n",
    "\n",
    "        Parameters:\n",
    "            base_dir (str): Base directory of the dataset.\n",
    "            seq_idx (str): Sequence index.\n",
    "            color_map_file (str): Path to the color map file.\n",
    "            view_status_file (str): Path to the view status file.\n",
    "            point_size (int): Point size for visualization.\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.seq_idx = seq_idx\n",
    "        self.color_map = self.load_color_map(color_map_file)\n",
    "        self.view_status_file = view_status_file\n",
    "        self.point_size = point_size\n",
    "        self.scan_dir = os.path.join(base_dir, seq_idx, \"velodyne\")\n",
    "        self.label_dir = os.path.join(base_dir, seq_idx, \"labels\")\n",
    "        self.pose_file = os.path.join(base_dir, seq_idx, \"poses.txt\")\n",
    "        self.scan_files = sorted(os.listdir(self.scan_dir))\n",
    "        self.label_files = sorted(os.listdir(self.label_dir))\n",
    "        self.pcd = o3d.geometry.PointCloud()\n",
    "        self.geometry_added = False\n",
    "        logging.info(\"SemanticKITTIVisualizer initialized\")\n",
    "\n",
    "    def load_color_map(self, color_map_file: str) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Loads the color map from a file.\n",
    "\n",
    "        Parameters:\n",
    "            color_map_file (str): Path to the color map file.\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, np.ndarray]: A dictionary mapping labels to colors.\n",
    "        \"\"\"\n",
    "        with open(color_map_file) as f:\n",
    "            color_map = json.load(f)\n",
    "        logging.info(\"Color map loaded\")\n",
    "        return {int(k): np.array(v, dtype=np.float32) / 255.0 for k, v in color_map.items()}\n",
    "\n",
    "    def read_bin(self, file_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reads a binary file and returns its contents as a numpy array.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): Path to the binary file.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Numpy array containing the contents of the file.\n",
    "        \"\"\"\n",
    "        return np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    def read_label(self, file_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reads a label file and returns its contents as a numpy array.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): Path to the label file.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Numpy array containing the semantic labels.\n",
    "        \"\"\"\n",
    "        label = np.fromfile(file_path, dtype=np.uint32)\n",
    "        sem_label = label & 0xFFFF  # Semantic label in lower half\n",
    "        return sem_label\n",
    "\n",
    "    def read_poses(self, file_path: str) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Reads a poses file and returns a list of transformation matrices.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): Path to the poses file.\n",
    "\n",
    "        Returns:\n",
    "            List[np.ndarray]: List of transformation matrices.\n",
    "        \"\"\"\n",
    "        poses = []\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                pose = np.fromstring(line, dtype=float, sep=' ').reshape(3, 4)\n",
    "                pose = np.vstack((pose, [0, 0, 0, 1]))\n",
    "                poses.append(pose)\n",
    "        return poses\n",
    "\n",
    "    def apply_transform(self, points: np.ndarray, transform: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies a transformation to a set of points.\n",
    "\n",
    "        Parameters:\n",
    "            points (np.ndarray): Numpy array of points.\n",
    "            transform (np.ndarray): Transformation matrix.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Transformed points.\n",
    "        \"\"\"\n",
    "        hom_points = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "        transformed_points = hom_points @ transform.T\n",
    "        return transformed_points[:, :3]\n",
    "\n",
    "    def update_point_cloud(self, vis: o3d.visualization.Visualizer, idx: int) -> None:\n",
    "        \"\"\"\n",
    "        Updates the point cloud for visualization without ego-motion compensation.\n",
    "\n",
    "        Parameters:\n",
    "            vis (o3d.visualization.Visualizer): Open3D visualizer.\n",
    "            idx (int): Index of the scan file to be visualized.\n",
    "        \"\"\"\n",
    "        scan_file = os.path.join(self.scan_dir, self.scan_files[idx])\n",
    "        label_file = os.path.join(self.label_dir, self.label_files[idx])\n",
    "        \n",
    "        points = self.read_bin(scan_file)[:, :3]\n",
    "        labels = self.read_label(label_file)\n",
    "        \n",
    "        if points.shape[0] == 0:\n",
    "            logging.warning(f\"No points found in scan {scan_file}\")\n",
    "            return\n",
    "        \n",
    "        colors = np.array([self.color_map.get(label, [0.5, 0.5, 0.5]) for label in labels])\n",
    "        \n",
    "        self.pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        self.pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        if self.geometry_added:\n",
    "            vis.remove_geometry(self.pcd, reset_bounding_box=False)\n",
    "        \n",
    "        vis.add_geometry(self.pcd, reset_bounding_box=not self.geometry_added)\n",
    "        self.geometry_added = True\n",
    "        \n",
    "        vis.update_renderer()\n",
    "        self.set_view_status(vis)\n",
    "        logging.info(f\"Frame {idx + 1}/{len(self.scan_files)} computed\")\n",
    "\n",
    "    def update_point_cloud_with_ego_motion(self, vis: o3d.visualization.Visualizer, idx: int) -> None:\n",
    "        \"\"\"\n",
    "        Updates the point cloud for visualization with ego-motion compensation.\n",
    "\n",
    "        Parameters:\n",
    "            vis (o3d.visualization.Visualizer): Open3D visualizer.\n",
    "            idx (int): Index of the scan file to be visualized.\n",
    "        \"\"\"\n",
    "        scan_file = os.path.join(self.scan_dir, self.scan_files[idx])\n",
    "        label_file = os.path.join(self.label_dir, self.label_files[idx])\n",
    "        \n",
    "        points = self.read_bin(scan_file)[:, :3]\n",
    "        labels = self.read_label(label_file)\n",
    "        \n",
    "        if points.shape[0] == 0:\n",
    "            logging.warning(f\"No points found in scan {scan_file}\")\n",
    "            return\n",
    "        \n",
    "        poses = self.read_poses(self.pose_file)\n",
    "        transformed_points = self.apply_transform(points, poses[idx])\n",
    "        \n",
    "        colors = np.array([self.color_map.get(label, [0.5, 0.5, 0.5]) for label in labels])\n",
    "        \n",
    "        self.pcd.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "        self.pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        if self.geometry_added:\n",
    "            vis.remove_geometry(self.pcd, reset_bounding_box=False)\n",
    "        \n",
    "        vis.add_geometry(self.pcd, reset_bounding_box=not self.geometry_added)\n",
    "        self.geometry_added = True\n",
    "        \n",
    "        vis.update_renderer()\n",
    "        self.set_view_status(vis)\n",
    "        logging.info(f\"Frame {idx + 1}/{len(self.scan_files)} computed with ego-motion compensation\")\n",
    "\n",
    "    def set_view_status(self, vis: o3d.visualization.Visualizer) -> None:\n",
    "        \"\"\"\n",
    "        Sets the view status of the visualizer.\n",
    "\n",
    "        Parameters:\n",
    "            vis (o3d.visualization.Visualizer): Open3D visualizer.\n",
    "        \"\"\"\n",
    "        with open(self.view_status_file) as f:\n",
    "            view_status = json.load(f)\n",
    "        sio = StringIO()\n",
    "        json.dump(view_status,sio)\n",
    "        view_status_string = sio.getvalue()\n",
    "        vis.set_view_status(view_status_string)\n",
    "        logging.info(\"View status loaded\")\n",
    "\n",
    "    def visualize(self) -> None:\n",
    "        \"\"\"\n",
    "        Visualizes the point cloud sequence without ego-motion compensation.\n",
    "        \"\"\"\n",
    "        vis = o3d.visualization.VisualizerWithKeyCallback()\n",
    "        vis.create_window(width=1920, height=1055)\n",
    "        \n",
    "        current_idx = [0]\n",
    "        self.update_point_cloud(vis, current_idx[0])\n",
    "        \n",
    "        coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=3.0, origin=[0, 0, 0])\n",
    "        vis.add_geometry(coordinate_frame)\n",
    "\n",
    "        def next(vis: o3d.visualization.Visualizer) -> None:\n",
    "            if current_idx[0] < len(self.scan_files) - 1:\n",
    "                current_idx[0] += 1\n",
    "                self.update_point_cloud(vis, current_idx[0])\n",
    "        \n",
    "        def prev(vis: o3d.visualization.Visualizer) -> None:\n",
    "            if current_idx[0] > 0:\n",
    "                current_idx[0] -= 1\n",
    "                self.update_point_cloud(vis, current_idx[0])\n",
    "        \n",
    "        def next20(vis: o3d.visualization.Visualizer):\n",
    "            stepsize = 20\n",
    "            if current_idx[0] < len(self.scan_files) -1 - stepsize:\n",
    "                current_idx[0] += stepsize\n",
    "                self.update_point_cloud(vis, current_idx[0])\n",
    "       \n",
    "        def prev20(vis: o3d.visualization.Visualizer):\n",
    "            stepsize = 20\n",
    "            if current_idx[0] < len(self.scan_files) -1 - stepsize:\n",
    "                current_idx[0] -= stepsize\n",
    "                self.update_point_cloud(vis, current_idx[0])\n",
    "        \n",
    "        vis.register_key_callback(262, next)\n",
    "        vis.register_key_callback(263, prev)\n",
    "        vis.register_key_callback(ord('N'),next20)\n",
    "        vis.register_key_callback(ord('B'),prev20)\n",
    "        \n",
    "        vis.get_render_option().background_color = np.array([0, 0, 0])\n",
    "        vis.get_render_option().point_size = self.point_size\n",
    "        \n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        self.set_view_status(vis)\n",
    "\n",
    "        vis.run()\n",
    "        vis.destroy_window()\n",
    "\n",
    "    def visualize_with_ego_motion(self) -> None:\n",
    "        \"\"\"\n",
    "        Visualizes the point cloud sequence with ego-motion compensation.\n",
    "        \"\"\"\n",
    "        vis = o3d.visualization.VisualizerWithKeyCallback()\n",
    "        vis.create_window(width=1920, height=1055)\n",
    "        \n",
    "        current_idx = [0]\n",
    "        self.update_point_cloud_with_ego_motion(vis, current_idx[0])\n",
    "        \n",
    "        coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=3.0, origin=[0, 0, 0])\n",
    "        vis.add_geometry(coordinate_frame)\n",
    "\n",
    "        def next(vis: o3d.visualization.Visualizer) -> None:\n",
    "            stepsize = 1\n",
    "            if current_idx[0] < len(self.scan_files) -1 - stepsize:\n",
    "                current_idx[0] += stepsize\n",
    "                self.update_point_cloud_with_ego_motion(vis, current_idx[0])\n",
    "        \n",
    "        def prev(vis: o3d.visualization.Visualizer) -> None:\n",
    "            stepsize = 1\n",
    "            if current_idx[0] >= stepsize :\n",
    "                current_idx[0] -= stepsize\n",
    "                self.update_point_cloud_with_ego_motion(vis, current_idx[0])\n",
    "        \n",
    "\n",
    "        def next20(vis: o3d.visualization.Visualizer):\n",
    "            stepsize = 20\n",
    "            if current_idx[0] < len(self.scan_files) -1 - stepsize:\n",
    "                current_idx[0] += stepsize\n",
    "                self.update_point_cloud_with_ego_motion(vis, current_idx[0])\n",
    "       \n",
    "        def prev20(vis: o3d.visualization.Visualizer):\n",
    "            stepsize = 20\n",
    "            if current_idx[0] < len(self.scan_files) -1 - stepsize:\n",
    "                current_idx[0] -= stepsize\n",
    "                self.update_point_cloud_with_ego_motion(vis, current_idx[0])\n",
    "        \n",
    "        vis.register_key_callback(262, next)\n",
    "        vis.register_key_callback(263, prev)\n",
    "        vis.register_key_callback(ord('N'),next20)\n",
    "        vis.register_key_callback(ord('B'),prev20)\n",
    "        \n",
    "        vis.get_render_option().background_color = np.array([0, 0, 0])\n",
    "        vis.get_render_option().point_size = self.point_size\n",
    "        \n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        self.set_view_status(vis)\n",
    "\n",
    "        vis.run()\n",
    "        vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 13:29:58,338 - INFO - Color map loaded\n",
      "2024-06-09 13:29:58,341 - INFO - SemanticKITTIVisualizer initialized\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"./dataset/sequences/\"\n",
    "    seq_idx = \"01\"\n",
    "    color_map_file = \"./color_map.json\"\n",
    "    view_status_file = \"./view_status.json\"\n",
    "    point_size = 3\n",
    "    \n",
    "    visualizer = SemanticKITTIVisualizer(base_dir, seq_idx, color_map_file, view_status_file, point_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Ego-motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 13:08:59,328 - INFO - Visualizing without ego-motion compensation\n",
      "2024-06-09 13:09:00,248 - INFO - View status loaded\n",
      "2024-06-09 13:09:00,248 - INFO - Frame 1/1101 computed\n",
      "2024-06-09 13:09:00,273 - INFO - View status loaded\n",
      "2024-06-09 13:09:13,676 - INFO - View status loaded\n",
      "2024-06-09 13:09:13,677 - INFO - Frame 21/1101 computed\n",
      "2024-06-09 13:09:14,531 - INFO - View status loaded\n",
      "2024-06-09 13:09:14,532 - INFO - Frame 41/1101 computed\n",
      "2024-06-09 13:09:16,236 - INFO - View status loaded\n",
      "2024-06-09 13:09:16,237 - INFO - Frame 21/1101 computed\n",
      "2024-06-09 13:09:17,161 - INFO - View status loaded\n",
      "2024-06-09 13:09:17,162 - INFO - Frame 1/1101 computed\n",
      "2024-06-09 13:09:18,225 - INFO - View status loaded\n",
      "2024-06-09 13:09:18,226 - INFO - Frame 2/1101 computed\n",
      "2024-06-09 13:09:19,161 - INFO - View status loaded\n",
      "2024-06-09 13:09:19,162 - INFO - Frame 3/1101 computed\n",
      "2024-06-09 13:09:19,890 - INFO - View status loaded\n",
      "2024-06-09 13:09:19,891 - INFO - Frame 4/1101 computed\n",
      "2024-06-09 13:09:20,640 - INFO - View status loaded\n",
      "2024-06-09 13:09:20,641 - INFO - Frame 5/1101 computed\n",
      "2024-06-09 13:09:21,291 - INFO - View status loaded\n",
      "2024-06-09 13:09:21,292 - INFO - Frame 6/1101 computed\n",
      "2024-06-09 13:09:21,898 - INFO - View status loaded\n",
      "2024-06-09 13:09:21,899 - INFO - Frame 7/1101 computed\n",
      "2024-06-09 13:09:22,739 - INFO - View status loaded\n",
      "2024-06-09 13:09:22,740 - INFO - Frame 8/1101 computed\n",
      "2024-06-09 13:09:23,425 - INFO - View status loaded\n",
      "2024-06-09 13:09:23,426 - INFO - Frame 9/1101 computed\n",
      "2024-06-09 13:09:26,544 - INFO - View status loaded\n",
      "2024-06-09 13:09:26,545 - INFO - Frame 10/1101 computed\n",
      "2024-06-09 13:09:30,250 - INFO - View status loaded\n",
      "2024-06-09 13:09:30,251 - INFO - Frame 11/1101 computed\n",
      "2024-06-09 13:09:33,423 - INFO - View status loaded\n",
      "2024-06-09 13:09:33,424 - INFO - Frame 12/1101 computed\n",
      "2024-06-09 13:09:41,638 - INFO - View status loaded\n",
      "2024-06-09 13:09:41,639 - INFO - Frame 32/1101 computed\n",
      "2024-06-09 13:09:43,182 - INFO - View status loaded\n",
      "2024-06-09 13:09:43,183 - INFO - Frame 52/1101 computed\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Visualizing without ego-motion compensation\")\n",
    "visualizer.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Ego-motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 13:30:01,583 - INFO - Visualizing with ego-motion compensation\n",
      "2024-06-09 13:30:02,504 - INFO - View status loaded\n",
      "2024-06-09 13:30:02,505 - INFO - Frame 1/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:02,530 - INFO - View status loaded\n",
      "2024-06-09 13:30:06,249 - INFO - View status loaded\n",
      "2024-06-09 13:30:06,250 - INFO - Frame 2/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:06,948 - INFO - View status loaded\n",
      "2024-06-09 13:30:06,950 - INFO - Frame 3/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:07,586 - INFO - View status loaded\n",
      "2024-06-09 13:30:07,587 - INFO - Frame 4/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:08,215 - INFO - View status loaded\n",
      "2024-06-09 13:30:08,216 - INFO - Frame 5/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:08,898 - INFO - View status loaded\n",
      "2024-06-09 13:30:08,899 - INFO - Frame 6/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:09,510 - INFO - View status loaded\n",
      "2024-06-09 13:30:09,511 - INFO - Frame 7/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:10,113 - INFO - View status loaded\n",
      "2024-06-09 13:30:10,115 - INFO - Frame 27/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:11,795 - INFO - View status loaded\n",
      "2024-06-09 13:30:11,795 - INFO - Frame 28/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:12,541 - INFO - View status loaded\n",
      "2024-06-09 13:30:12,542 - INFO - Frame 29/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:15,737 - INFO - View status loaded\n",
      "2024-06-09 13:30:15,738 - INFO - Frame 30/1101 computed with ego-motion compensation\n",
      "2024-06-09 13:30:16,908 - INFO - View status loaded\n",
      "2024-06-09 13:30:16,909 - INFO - Frame 50/1101 computed with ego-motion compensation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Visualizing with ego-motion compensation\")\n",
    "visualizer.visualize_with_ego_motion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
